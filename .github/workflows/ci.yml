# GitHub Actions CI/CD Pipeline for Telegram Toolkit MCP
# See https://docs.github.com/en/actions

name: CI

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

jobs:
  # Quality Checks
  quality:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Cache pip dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev,observability]"

    - name: Run pre-commit hooks
      run: |
        pre-commit run --all-files --show-diff-on-failure

    - name: Run type checking (mypy)
      run: |
        mypy src/telegram_toolkit_mcp --ignore-missing-imports

    - name: Run linting (ruff)
      run: |
        ruff check src/telegram_toolkit_mcp tests
        ruff format --check src/telegram_toolkit_mcp tests

  # Unit Tests
  test-unit:
    runs-on: ubuntu-latest
    needs: quality
    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Cache pip dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev,observability]"

    - name: Run unit tests
      run: |
        pytest tests/unit/ -v --cov=telegram_toolkit_mcp --cov-report=xml --cov-report=term

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v4
      with:
        file: ./coverage.xml
        flags: unit-tests
        name: unit-tests-coverage

  # Integration Tests
  test-integration:
    runs-on: ubuntu-latest
    needs: quality
    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Cache pip dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev,observability]"

    - name: Run integration tests
      run: |
        pytest tests/integration/ -v --cov=telegram_toolkit_mcp --cov-report=xml --cov-report=term
      env:
        TELEGRAM_API_ID: ${{ secrets.TELEGRAM_API_ID }}
        TELEGRAM_API_HASH: ${{ secrets.TELEGRAM_API_HASH }}

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v4
      with:
        file: ./coverage.xml
        flags: integration-tests
        name: integration-tests-coverage

  # Security Scan
  security:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4

    - name: Run Bandit security scanner
      uses: PyCQA/bandit-action@v1
      with:
        path: "src/telegram_toolkit_mcp"
        options: "--format json --output bandit-report.json"

    - name: Upload Bandit results
      uses: actions/upload-artifact@v4
      with:
        name: bandit-report
        path: bandit-report.json

    - name: Check for secrets
      uses: gitleaks/gitleaks-action@v2
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  # Build and Package
  build:
    runs-on: ubuntu-latest
    needs: [quality, test-unit, test-integration]
    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Install build dependencies
      run: |
        python -m pip install --upgrade pip
        pip install build twine

    - name: Build package
      run: python -m build

    - name: Check package
      run: twine check dist/*

    - name: Upload build artifacts
      uses: actions/upload-artifact@v4
      with:
        name: dist
        path: dist/

  # Release (only on main branch and tags)
  release:
    runs-on: ubuntu-latest
    needs: build
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    steps:
    - uses: actions/checkout@v4

    - name: Download build artifacts
      uses: actions/download-artifact@v4
      with:
        name: dist
        path: dist/

    - name: Publish to PyPI
      if: github.event_name == 'push' && contains(github.ref, 'refs/tags/')
      uses: pypa/gh-action-pypi-publish@release/v1
      with:
        user: __token__
        password: ${{ secrets.PYPI_API_TOKEN }}

  # Documentation
  docs:
    runs-on: ubuntu-latest
    needs: quality
    if: github.ref == 'refs/heads/main'
    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Install documentation dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev]"
        pip install sphinx sphinx-rtd-theme

    - name: Build documentation
      run: |
        cd docs
        sphinx-build -b html . _build/html

    - name: Deploy documentation to GitHub Pages
      if: github.ref == 'refs/heads/main'
      uses: peaceiris/actions-gh-pages@v4
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        publish_dir: docs/_build/html

  # Performance Benchmark
  benchmark:
    runs-on: ubuntu-latest
    needs: test-unit
    if: github.ref == 'refs/heads/main'
    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev,observability]"

    - name: Run performance benchmarks
      run: |
        python -m pytest tests/ -k "benchmark" --benchmark-only --benchmark-json=benchmark.json

    - name: Upload benchmark results
      uses: actions/upload-artifact@v4
      with:
        name: benchmark-results
        path: benchmark.json
